{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c004a8-0e83-4a0f-8765-cb35facdaf5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/anaconda3/envs/cgnn/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170416\n",
      "(173, 23140, 8)\n",
      "(23140, 8)\n",
      "(144, 8, 30, 23140)\n",
      "(144, 23140)\n",
      "12\n",
      "torch.Size([108, 8, 30, 23140]) torch.Size([12, 8, 30, 23140]) torch.Size([24, 8, 30, 23140])\n",
      "torch.Size([108, 23140]) torch.Size([12, 23140]) torch.Size([24, 23140])\n",
      "torch.Size([23140, 12])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import dgl\n",
    "import os\n",
    "from dgl.data import DGLDataset\n",
    "from def_load_data import get_model_data\n",
    "from TC_EGAT import TTST_module\n",
    "\n",
    "device = (\n",
    "    torch.device(\"cuda\")\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "device = torch.device(\"cpu\")\n",
    "ss_x,ss_y,x_train,y_train,x_val,y_val,x_test,y_test,nor_sta_fes,nor_edge_fes,G = get_model_data(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "279969f5-f367-4411-aae0-2ad65084ce20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "10 9\n",
      "torch.Size([108, 8, 30, 23140]) torch.Size([108, 23140])\n",
      "torch.Size([24, 8, 30, 23140]) torch.Size([24, 23140])\n",
      "torch.Size([102, 8, 30, 23140])\n"
     ]
    }
   ],
   "source": [
    "from def_load_data import generate_dt_points\n",
    "date_list = generate_dt_points('20160409','20221210')\n",
    "y_dt = date_list[31:]\n",
    "train_dt = y_dt[:130]\n",
    "val_dt = y_dt[130:130+14]\n",
    "test_dt = y_dt[130+14:130+14+29]\n",
    "print(len(test_dt))\n",
    "#test_dt  #130,13,30=173\n",
    "#print(test_dt)\n",
    "lack_dt_train = ['D20171001','D20171013','D20190418','D20190430','D20191003','D20191015','D20201126','D20201208','D20210302', 'D20210314']\n",
    "lack_dt_test = ['D20220520','D20220601','D20220625','D20220707','D20220719','D20220731','D20220812','D20220905','D20220917','D20221222']\n",
    "lack_dt_idx_train = []\n",
    "lack_dt_idx_test = []\n",
    "for i,dtc in enumerate(train_dt):\n",
    "    for l_dt in lack_dt_train:\n",
    "        if l_dt[1:] ==str(dtc):\n",
    "            lack_dt_idx_train.append(i)\n",
    "for i,dtc in enumerate(test_dt):\n",
    "    for l_dt in lack_dt_test:\n",
    "        if l_dt[1:] ==str(dtc):\n",
    "            lack_dt_idx_test.append(i)\n",
    "            \n",
    "print(len(lack_dt_idx_train),len(lack_dt_idx_test))\n",
    "\n",
    "\n",
    "lack_dt_idx_train = torch.tensor(lack_dt_idx_train)\n",
    "lack_dt_idx_test = torch.tensor(lack_dt_idx_test)\n",
    "\n",
    "train_keep = torch.tensor([i for i in range(x_train.size(0)) if i not in lack_dt_idx_train]).to(device)\n",
    "test_keep = torch.tensor([i for i in range(x_test.size(0)) if i not in lack_dt_idx_test]).to(device)\n",
    "\n",
    "# 删除指定索引的数据\n",
    "x_train_d = torch.index_select(x_train, 0, train_keep)\n",
    "y_train_d = torch.index_select(y_train, 0, train_keep)\n",
    "\n",
    "x_test_d = torch.index_select(x_test, 0, test_keep)\n",
    "y_test_d = torch.index_select(y_test, 0, test_keep)\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)\n",
    "print(x_train_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22b54ba4-596d-4053-8b84-a0c6e61bd009",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "8 9\n",
      "torch.Size([108, 8, 30, 23140]) torch.Size([108, 23140])\n",
      "torch.Size([15, 8, 30, 23140]) torch.Size([15, 23140])\n",
      "torch.Size([100, 8, 30, 23140])\n"
     ]
    }
   ],
   "source": [
    "from load_data import generate_dt_points\n",
    "date_list = generate_dt_points('20160409','20221210')\n",
    "y_dt = date_list[31+30:]\n",
    "train_dt = y_dt[:108]\n",
    "val_dt = y_dt[108:108+12]\n",
    "test_dt = y_dt[108+12:108+12+24]\n",
    "print(len(test_dt))\n",
    "\n",
    "lack_dt_train = ['D20171001','D20171013','D20190418','D20190430','D20191003','D20191015','D20201126','D20201208','D20210302', 'D20210314']\n",
    "lack_dt_test = ['D20220520','D20220601','D20220625','D20220707','D20220719','D20220731','D20220812','D20220905','D20220917']\n",
    "lack_dt_idx_train = []\n",
    "lack_dt_idx_test = []\n",
    "for i,dtc in enumerate(train_dt):\n",
    "    for l_dt in lack_dt_train:\n",
    "        if l_dt[1:] ==str(dtc):\n",
    "            lack_dt_idx_train.append(i)\n",
    "for i,dtc in enumerate(test_dt):\n",
    "    for l_dt in lack_dt_test:\n",
    "        if l_dt[1:] ==str(dtc):\n",
    "            lack_dt_idx_test.append(i)\n",
    "            \n",
    "print(len(lack_dt_idx_train),len(lack_dt_idx_test))\n",
    "\n",
    "lack_dt_idx_train = torch.tensor(lack_dt_idx_train)\n",
    "lack_dt_idx_test = torch.tensor(lack_dt_idx_test)\n",
    "\n",
    "train_keep = torch.tensor([i for i in range(x_train.size(0)) if i not in lack_dt_idx_train]).to(device)\n",
    "test_keep = torch.tensor([i for i in range(x_test.size(0)) if i not in lack_dt_idx_test]).to(device)\n",
    "\n",
    "# 删除指定索引的数据\n",
    "x_train_d = torch.index_select(x_train, 0, train_keep)\n",
    "y_train_d = torch.index_select(y_train, 0, train_keep)\n",
    "\n",
    "x_test_d = torch.index_select(x_test, 0, test_keep)\n",
    "y_test_d = torch.index_select(y_test, 0, test_keep)\n",
    "\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test_d.shape,y_test_d.shape)\n",
    "print(x_train_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28bba6fe-5b56-411e-8c19-c1a9dde2d03e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_data = torch.utils.data.TensorDataset(x_train_d, y_train_d)\n",
    "train_iter = torch.utils.data.DataLoader(train_data, batch_size)\n",
    "val_data = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "val_iter = torch.utils.data.DataLoader(val_data, batch_size)\n",
    "test_data = torch.utils.data.TensorDataset(x_test_d, y_test_d)\n",
    "test_iter = torch.utils.data.DataLoader(test_data, batch_size)\n",
    "\n",
    "#del x_train,y_train,x_val,y_val,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c7bd7a-c55f-432b-a562-f8d41f8b2eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 11, 30, 23140])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "999c66d0-447d-48ac-bf30-e9306db798f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "train_data = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_iter = torch.utils.data.DataLoader(train_data, batch_size)\n",
    "val_data = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "val_iter = torch.utils.data.DataLoader(val_data, batch_size)\n",
    "test_data = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "test_iter = torch.utils.data.DataLoader(test_data, batch_size)\n",
    "\n",
    "#del x_train,y_train,x_val,y_val,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9477e028-e531-4c11-af09-313f5285ee84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 数量: 2\n"
     ]
    }
   ],
   "source": [
    "gpu_count = torch.cuda.device_count()\n",
    "print(\"GPU 数量:\", gpu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd33e00f-e081-4e70-b262-f60fa678bb66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: T1.convT.bias, Parameters: 32\n",
      "Layer: T1.convT.weight_g, Parameters: 32\n",
      "Layer: T1.convT.weight_v, Parameters: 768\n",
      "Layer: T1.conv.weight, Parameters: 768\n",
      "Layer: T1.conv.bias, Parameters: 32\n",
      "Layer: S1.fc1.weight, Parameters: 144\n",
      "Layer: S1.fc1.bias, Parameters: 12\n",
      "Layer: S1.convS.weight, Parameters: 144\n",
      "Layer: S1.convS.bias, Parameters: 12\n",
      "Layer: T2.convT.bias, Parameters: 64\n",
      "Layer: T2.convT.weight_g, Parameters: 64\n",
      "Layer: T2.convT.weight_v, Parameters: 8448\n",
      "Layer: T2.conv.weight, Parameters: 8448\n",
      "Layer: T2.conv.bias, Parameters: 64\n",
      "Layer: S2.bottleneck.node.weight, Parameters: 3072\n",
      "Layer: S2.bottleneck.node.bias, Parameters: 48\n",
      "Layer: S2.bottleneck.edge.weight, Parameters: 64\n",
      "Layer: S2.bottleneck.edge.bias, Parameters: 16\n",
      "Layer: S2.egat.a_h_node, Parameters: 120\n",
      "Layer: S2.egat.a_e_node, Parameters: 24\n",
      "Layer: S2.egat.a_h_edge, Parameters: 120\n",
      "Layer: S2.egat.a_e_edge, Parameters: 24\n",
      "Layer: S2.egat.bias1, Parameters: 48\n",
      "Layer: S2.egat.bias2, Parameters: 16\n",
      "Layer: S2.egat.fh_n.weight, Parameters: 5760\n",
      "Layer: S2.egat.fe_n.weight, Parameters: 384\n",
      "Layer: S2.egat.fh_e.weight, Parameters: 5760\n",
      "Layer: S2.egat.fe_e.weight, Parameters: 384\n",
      "Layer: S2.pred.fc1.weight, Parameters: 3072\n",
      "Layer: S2.pred.fc1.bias, Parameters: 64\n",
      "Layer: S2.pred.fc2.weight, Parameters: 3072\n",
      "Layer: S2.pred.fc2.bias, Parameters: 48\n",
      "Layer: S2.merge.fc1.weight, Parameters: 4608\n",
      "Layer: S2.merge.fc1.bias, Parameters: 48\n",
      "Layer: S2.merge.fc2.weight, Parameters: 512\n",
      "Layer: S2.merge.fc2.bias, Parameters: 16\n",
      "Layer: T3.convT.bias, Parameters: 64\n",
      "Layer: T3.convT.weight_g, Parameters: 64\n",
      "Layer: T3.convT.weight_v, Parameters: 9216\n",
      "Layer: T3.conv.weight, Parameters: 9216\n",
      "Layer: T3.conv.bias, Parameters: 64\n",
      "Layer: out.tconv1.weight, Parameters: 65536\n",
      "Layer: out.tconv1.bias, Parameters: 64\n",
      "Layer: out.tconv2.weight, Parameters: 4096\n",
      "Layer: out.tconv2.bias, Parameters: 64\n",
      "Layer: out.fc.conv.weight, Parameters: 64\n",
      "Layer: out.fc.conv.bias, Parameters: 1\n"
     ]
    }
   ],
   "source": [
    "c_in, c_out,sta_fes, sta_h1 = 8,32,12,12\n",
    "droput = 0.5\n",
    "device = torch.device(\"cuda:1\")\n",
    "tcg = TTST_module(c_in, c_out,sta_fes, sta_h1,droput).to(device)\n",
    "\n",
    "total_params = 0\n",
    "for name, param in tcg.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        param_params = param.numel()\n",
    "        total_params += param_params\n",
    "        print(f\"Layer: {name}, Parameters: {param_params}\")\n",
    "\n",
    "#print(f\"Total Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01371b74-625e-407e-af55-22da55643c5d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 , train loss: 0.06708807537332177\n",
      "epoch 2 , train loss: 0.058506665471941235\n",
      "epoch 3 , train loss: 0.04014071312732995\n",
      "epoch 4 , train loss: 0.03153025611303747\n",
      "epoch 5 , train loss: 0.036073939362540844\n",
      "epoch 6 , train loss: 0.0331950337998569\n",
      "epoch 7 , train loss: 0.03045784207060933\n",
      "epoch 8 , train loss: 0.02770428204908967\n",
      "epoch 9 , train loss: 0.028000535517930983\n",
      "epoch 10 , train loss: 0.02794991442002356\n",
      "epoch 11 , train loss: 0.02638637657277286\n",
      "epoch 12 , train loss: 0.025904695512726904\n",
      "epoch 13 , train loss: 0.025873503303155302\n",
      "epoch 14 , train loss: 0.026332028750330208\n",
      "epoch 15 , train loss: 0.026918902099132537\n",
      "epoch 16 , train loss: 0.025186858074739575\n",
      "epoch 17 , train loss: 0.024340509325265883\n",
      "epoch 18 , train loss: 0.023840955309569836\n",
      "epoch 19 , train loss: 0.023627537665888668\n",
      "epoch 20 , train loss: 0.023315162928774953\n",
      "epoch 21 , train loss: 0.023000294882804154\n",
      "epoch 22 , train loss: 0.02273289976641536\n",
      "epoch 23 , train loss: 0.022483134707435966\n",
      "epoch 24 , train loss: 0.0220942959561944\n",
      "epoch 25 , train loss: 0.021819517882540822\n",
      "epoch 26 , train loss: 0.02167502340860665\n",
      "epoch 27 , train loss: 0.02178320338949561\n",
      "epoch 28 , train loss: 0.02174461026675999\n",
      "epoch 29 , train loss: 0.0213234855607152\n",
      "epoch 30 , train loss: 0.021622195718809963\n",
      "epoch 31 , train loss: 0.021392574282363058\n",
      "epoch 32 , train loss: 0.021004561567679048\n",
      "epoch 33 , train loss: 0.021285376269370316\n",
      "epoch 34 , train loss: 0.020704280473291873\n",
      "epoch 35 , train loss: 0.02059322859160602\n",
      "epoch 36 , train loss: 0.020700642997398974\n",
      "epoch 37 , train loss: 0.020381559059023856\n",
      "epoch 38 , train loss: 0.020181975364685058\n",
      "epoch 39 , train loss: 0.020877037141472102\n",
      "epoch 40 , train loss: 0.02054808718152344\n",
      "epoch 41 , train loss: 0.020167508665472268\n",
      "epoch 42 , train loss: 0.01973792113363743\n",
      "epoch 43 , train loss: 0.020641183825209738\n",
      "epoch 44 , train loss: 0.01926223438233137\n",
      "epoch 45 , train loss: 0.018734823567792772\n",
      "epoch 46 , train loss: 0.01857095048762858\n",
      "epoch 47 , train loss: 0.01908675881102681\n",
      "epoch 48 , train loss: 0.01847544863820076\n",
      "epoch 49 , train loss: 0.01815996279940009\n",
      "epoch 50 , train loss: 0.01922858351841569\n",
      "epoch 51 , train loss: 0.018435806268826127\n",
      "epoch 52 , train loss: 0.017868473567068575\n",
      "epoch 53 , train loss: 0.018993188198655843\n",
      "epoch 54 , train loss: 0.01803156186826527\n",
      "epoch 55 , train loss: 0.017411623680964113\n",
      "epoch 56 , train loss: 0.018201329093426467\n",
      "epoch 57 , train loss: 0.01790421918965876\n",
      "epoch 58 , train loss: 0.01727118090726435\n",
      "epoch 59 , train loss: 0.017878371328115462\n",
      "epoch 60 , train loss: 0.018510358007624746\n",
      "epoch 61 , train loss: 0.01693571367301047\n",
      "epoch 62 , train loss: 0.016670917943120003\n",
      "epoch 63 , train loss: 0.016515032611787318\n",
      "epoch 64 , train loss: 0.016364768566563725\n",
      "epoch 65 , train loss: 0.016326608676463364\n",
      "epoch 66 , train loss: 0.016283783642575145\n",
      "epoch 67 , train loss: 0.01582318655215204\n",
      "epoch 68 , train loss: 0.016461261892691256\n",
      "epoch 69 , train loss: 0.0167781477374956\n",
      "epoch 70 , train loss: 0.01646963769569993\n",
      "epoch 71 , train loss: 0.015794518571346998\n",
      "epoch 72 , train loss: 0.01691504616290331\n",
      "epoch 73 , train loss: 0.01593206038698554\n",
      "epoch 74 , train loss: 0.015326008033007384\n",
      "epoch 75 , train loss: 0.015738185681402683\n",
      "epoch 76 , train loss: 0.016225988720543684\n",
      "epoch 77 , train loss: 0.015232982831075787\n",
      "epoch 78 , train loss: 0.014832949154078961\n",
      "epoch 79 , train loss: 0.01472216541878879\n",
      "epoch 80 , train loss: 0.014701026817783713\n",
      "epoch 81 , train loss: 0.014717180794104934\n",
      "epoch 82 , train loss: 0.014708037124946713\n",
      "epoch 83 , train loss: 0.014705459140241146\n",
      "epoch 84 , train loss: 0.014722046321257948\n",
      "epoch 85 , train loss: 0.014704410452395678\n",
      "epoch 86 , train loss: 0.014702730802819133\n",
      "epoch 87 , train loss: 0.014680892787873745\n",
      "epoch 88 , train loss: 0.014684083089232445\n",
      "epoch 89 , train loss: 0.014702577022835612\n",
      "epoch 90 , train loss: 0.01469796578399837\n",
      "epoch 91 , train loss: 0.014699796997010708\n",
      "epoch 92 , train loss: 0.01473202102817595\n",
      "epoch 93 , train loss: 0.01470195417292416\n",
      "epoch 94 , train loss: 0.014712146278470754\n",
      "epoch 95 , train loss: 0.014705836828798056\n",
      "epoch 96 , train loss: 0.014727614596486091\n",
      "epoch 97 , train loss: 0.014706142581999301\n",
      "epoch 98 , train loss: 0.014701651129871606\n",
      "epoch 99 , train loss: 0.014714797576889396\n",
      "epoch 100 , train loss: 0.014695415860041977\n"
     ]
    }
   ],
   "source": [
    "loss = nn.MSELoss()\n",
    "lr =0.0008\n",
    "optimizer = torch.optim.Adam(tcg.parameters(), lr=lr,weight_decay = 5e-5)  #RMSprop\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.8)\n",
    "\n",
    "save_path = \"TC_EGAT.pth\"\n",
    "min_val_loss = np.inf\n",
    "scaler = GradScaler()\n",
    "\n",
    "G = G.to(device)\n",
    "nor_sta_fes = nor_sta_fes.to(device)\n",
    "nor_edge_fes = nor_edge_fes.to(device)\n",
    "#x_val,y_val = x_val.to(device),y_val.to(device)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "for epoch in range(1, 200 + 1):\n",
    "    l_sum, n = 0.0, 0\n",
    "    tcg.train()\n",
    "    for x, y in train_iter:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            y_pred = tcg(G, x, nor_sta_fes,nor_edge_fes)\n",
    "            l = loss(y_pred, y)\n",
    "        #l.backward()\n",
    "        #optimizer.step()\n",
    "        scaler.scale(l).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        l_sum += l.item() * y.shape[0]\n",
    "        n += y.shape[0]\n",
    "    scheduler.step()\n",
    "\n",
    "    val_loss = 0\n",
    "    '''\n",
    "    for x, y in val_iter:\n",
    "        x,y= x.to(device),y.to(device)\n",
    "        with autocast():\n",
    "            val_pre = tcg(G, x, nor_sta_fes,nor_edge_fes)\n",
    "        val_loss1 = loss(val_pre,y).item()\n",
    "        val_loss += val_loss1* y.shape[0]\n",
    "    if val_loss < min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(tcg.state_dict(), save_path)\n",
    "    '''\n",
    "\n",
    "    print(\"epoch\",epoch,\", train loss:\",l_sum / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533e7d83-bff6-4ce7-8b26-c3d089352ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feffa39-0915-4d87-8ee1-ed57432b6585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57820f-6cf8-46c8-9069-c75807958448",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgnn",
   "language": "python",
   "name": "cgnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
